# Hebbia Datadog Explorer

**Tool:** `cd ~/Hebbia/sisu-notes && .venv/bin/python tools/datadog_explorer.py`

Query metrics, logs, and APM traces from Datadog. API keys in `tools/config.py`.

## ðŸ”— Direct Web UI URLs (Built-in)

**NEW: The Python tool now generates clickable URLs automatically!** Every query displays a direct link to the Datadog web UI at the end of the results.

### Automatic URL Generation

```bash
# URLs are now generated by default for all queries
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe 2h
# Output format (simplified):
# ðŸ“ logs:run_get_rows_db_queries [2h]
# â†’ 100 log entries found
# 
#   [1] 2025-09-01 23:30:29 | sheets | info
#       run_get_rows_db_queries performance
#       DB: 0.4345s | Cache: True | Rows: 467
# 
# ðŸ”— https://app.datadoghq.com/logs?query=...

# Show direct links to individual log events (NEW!)
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --event-urls
# Each log entry includes: ðŸ”— Direct link: https://app.datadoghq.com/logs?query=...&event=...

# Hide URLs if not needed
.venv/bin/python tools/datadog_explorer.py "logs:error" --no-url

# URLs work for all query types:
# - Logs: logs:*
# - APM Traces: traces:* or spans:*
# - Metrics: any metric query
```

### URL Format Reference

```
# Log Explorer URLs (general view)
https://app.datadoghq.com/logs?query=[QUERY]&from_ts=[MS]&to_ts=[MS]&live=true

# Log Explorer URLs (specific event) - NEW!
https://app.datadoghq.com/logs?query=[QUERY]&event=[EVENT_ID]&from_ts=[MS]&to_ts=[MS]
# Full params: &agg_m=count&cols=host%2Cservice&messageDisplay=inline&viz=stream&live=true

# APM Trace URLs
https://app.datadoghq.com/apm/traces?query=[QUERY]&start=[MS]&end=[MS]&paused=true

# Metrics Explorer URLs
https://app.datadoghq.com/metric/explorer?from_ts=[SEC]&to_ts=[SEC]&live=true&query=[QUERY]
```

## Essential Commands

### ðŸ” Performance Investigation
```bash
# Get_rows performance logs (from final_report.md investigation)
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe 2h

# Find slow queries (>1 second)
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --raw | \
  jq '.data[] | select(.attributes.attributes.total_db_queries_time > 1)'

# Performance distribution analysis
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --raw | \
  jq -r '.data[].attributes.attributes.total_db_queries_time' | \
  awk '{if($1<0.1) fast++; else if($1<1) normal++; else slow++} 
       END {printf "Fast: %d, Normal: %d, Slow: %d\n", fast, normal, slow}'

# Count occurrences of specific log patterns
.venv/bin/python tools/datadog_explorer.py "logs:\"slow get_relevant_rows query\"" --timeframe 24h --raw | \
  jq -r '.data | length'  # Returns up to 100 (API limit)

# Advanced performance queries with cache hits and slow relevant_rows
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries performance @cache_hit:true @relevant_rows_time:>5" --timeframe 1d

# Get event URLs for detailed trace viewing
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries @relevant_rows_time:>5" --event-urls

# Extract trace IDs and event details for SQL analysis
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries @relevant_rows_time:>5" --raw | \
  jq -r '.data[0:10] | .[] | {id: .id, timestamp: .attributes.timestamp, relevant_rows_time: .attributes.attributes.relevant_rows_time, trace_id: .attributes.attributes.dd.trace_id}'
```

### ðŸ“ Log Queries
```bash
# Basic log search
.venv/bin/python tools/datadog_explorer.py "logs:keyword"

# Service errors
.venv/bin/python tools/datadog_explorer.py "logs:service:sheets status:error"

# Complex filters
.venv/bin/python tools/datadog_explorer.py "logs:service:sheets run_get_rows_db_queries"

# Raw JSON for analysis
.venv/bin/python tools/datadog_explorer.py "logs:query" --raw
```

### ðŸ“Š Metrics
```bash
# Database performance
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.connections{*}"
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.query.time{*}"
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.max_connections{*}"
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.percent_usage_connections{*}"

# Database trace metrics (APM)
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.connect{*}"
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.query.time{*}"
.venv/bin/python tools/datadog_explorer.py "percentile:trace.postgres.query.time{*}:95"
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.query.rows{*}"

# API latency
.venv/bin/python tools/datadog_explorer.py "avg:trace.request.duration{service:hebbia-api}"
.venv/bin/python tools/datadog_explorer.py "percentile:trace.request.duration{service:sheets}:95"

# System resources
.venv/bin/python tools/datadog_explorer.py "avg:system.cpu.idle{*}"
.venv/bin/python tools/datadog_explorer.py "avg:system.mem.used{*}"
```

### ðŸ”Ž Discovery
```bash
# List all metrics
.venv/bin/python tools/datadog_explorer.py "list-metrics"

# Search specific metrics
.venv/bin/python tools/datadog_explorer.py "list-metrics" --search "postgres"
.venv/bin/python tools/datadog_explorer.py "list-metrics" --search "trace"

# Get metric details
.venv/bin/python tools/datadog_explorer.py "info:postgresql.connections"
```

### ðŸ”¬ APM Traces (NEW)
```bash
# Query application traces
.venv/bin/python tools/datadog_explorer.py "traces:service:sheets" --timeframe 1h
# Output format:
# ðŸ” traces:service:sheets [1h]
# â†’ 50 trace spans found
#   [1] 2025-09-01 22:37:59 | sheets | sheets.api.matrix_api.get_rows | 2357.81ms

# Filter traces by duration (in nanoseconds)
.venv/bin/python tools/datadog_explorer.py "traces:service:sheets @duration:>1000000000" --timeframe 1h

# Get raw trace data for analysis
.venv/bin/python tools/datadog_explorer.py "traces:service:sheets" --raw | \
  jq '.data[].attributes | {resource_name, duration: .custom.duration}'

# Note: Database operations are not captured as separate spans
# Use application logs for database performance analysis instead
```

## Query Syntax

### Trace Query Syntax (NEW)
- **Prefix**: All trace queries start with `traces:`
- **Service**: `traces:service:sheets`
- **Duration**: `traces:@duration:>1000000000` (in nanoseconds, >1s)
- **Environment**: `traces:env:prod`
- **Combined**: `traces:service:sheets @duration:>1000000000`
- **Raw output**: Add `--raw` for JSON analysis with jq

### Log Query Syntax
- **Prefix**: All log queries start with `logs:`
- **Service**: `logs:service:sheets`
- **Status**: `logs:status:error` or `logs:status:warn`
- **Host**: `logs:host:ip-10-1-1-188`
- **Tags**: `logs:@tagname:value`
- **Text**: `logs:"exact phrase"` or `logs:keyword`
- **Multiple**: `logs:service:sheets status:error`

### Metric Aggregations
- `avg:` - Average
- `sum:` - Total
- `min:` / `max:` - Min/Max
- `count:` - Count
- `percentile:metric{*}:95` - 95th percentile

### Modifiers
- `.as_rate()` - Convert to rate/sec
- `.as_count()` - Convert to count
- `.rollup(avg, 60)` - 60s buckets
- `by {tag}` - Group by tag

### Timeframes

#### Relative Time (from now)
- Minutes: `5m`, `15m`, `30m`
- Hours: `1h` (default), `2h`, `4h`, `8h`, `12h`
- Days: `1d`, `2d`, `7d`, `14d`, `30d`

#### Custom Time Ranges (NEW!)
- **Single day**: `--timeframe "2025-01-03"` (entire day)
- **Date range**: `--timeframe "2025-01-03,2025-01-05"` (Jan 3-5)
- **ISO datetime**: `--timeframe "2025-01-03T10:00:00,2025-01-03T18:00:00"` (specific hours)
- **Unix seconds**: `--timeframe "1754539200,1754711999"` (epoch timestamps)
- **Unix milliseconds**: `--timeframe "1754539200000,1754711999999"` (auto-detected)

```bash
# Examples with custom timeframes
.venv/bin/python tools/datadog_explorer.py "logs:error" --timeframe "2025-01-03"
.venv/bin/python tools/datadog_explorer.py "logs:error" --timeframe "2025-01-03,2025-01-05"
.venv/bin/python tools/datadog_explorer.py "logs:error" --timeframe "1754539200000,1754711999999"
```

## Database Connection Analysis

### PostgreSQL Metrics
```bash
# Connection pool usage
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.connections{*}" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "max:postgresql.connections{*}" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.percent_usage_connections{*}" --timeframe 2h

# Connection performance (from APM traces)
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.connect{*}" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "max:trace.postgres.connect{*}" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "percentile:trace.postgres.connect{*}:95" --timeframe 2h

# Query performance
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.query.time{*}" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "percentile:trace.postgres.query.time{*}:95" --timeframe 2h
.venv/bin/python tools/datadog_explorer.py "percentile:trace.postgres.query.time{*}:99" --timeframe 2h

# Connection analysis with filters
.venv/bin/python tools/datadog_explorer.py "avg:postgresql.connections{env:prod}" --timeframe 1h
.venv/bin/python tools/datadog_explorer.py "avg:trace.postgres.connect{env:prod,service:sheets}" --timeframe 1h
```

## Analysis Patterns

### ðŸ” Systematic Performance Investigation Method

**The 4-Step Investigation Pattern**:
1. **Look at the code** â†’ Find where logging happens
2. **Discover attributes** â†’ Extract all logged fields from Datadog
3. **Experiment with filters** â†’ Try various attribute combinations
4. **Report insights** â†’ Document correlations and bottlenecks

### Step 1: Find the Logging Code

**Example Source**: `mono/sheets/cortex/ssrm/get_rows_utils.py`
```python
# Look for logging patterns like:
logger.info("run_get_rows_db_queries performance", extra={
    "cache_hit": cache_hit,
    "relevant_rows_time": relevant_rows_time,
    "total_db_queries_time": total_time,
    "matrix_size_category": matrix_category,
    # ... more attributes
})
```

### Step 2: Discover All Available Attributes

```bash
# Extract all logged attributes from any log pattern
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe 1h --raw | \
  jq -r '.data[0].attributes.attributes | keys[]' | sort

# Common attributes found:
# cache_hit, cache_total_time, columns_queried
# filter_count, group_depth, has_filtering, has_group_loading
# has_grouping, has_pagination, has_sorting, hydration_time
# is_full_matrix_search, matrix_size_category, matrix_total_columns
# matrix_total_rows, relevant_rows_time, total_db_queries_time, total_row_count
```

### Step 3: Experiment with Filter Combinations

```bash
# Basic performance queries
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @total_db_queries_time:>10" --timeframe 1d

# Correlation testing - find what makes queries slow
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @has_pagination:true @relevant_rows_time:>5" --timeframe 1d
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @has_pagination:false @relevant_rows_time:>5" --timeframe 1d

# Matrix size impact
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @matrix_size_category:large @cache_hit:true" --timeframe 1d

# Feature combination impact
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @has_grouping:true @has_sorting:true" --timeframe 1d

# Cache effectiveness
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @cache_hit:true @relevant_rows_time:>5" --timeframe 1d
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @cache_hit:false @relevant_rows_time:>5" --timeframe 1d
```

### Step 4: Analyze and Report Insights

```bash
# Count queries by different criteria
echo "=== Performance Correlation Analysis ==="

# Test hypothesis: pagination causes slowness
echo "Slow queries WITH pagination:"
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @has_pagination:true @relevant_rows_time:>5" --raw | jq '.data | length'

echo "Slow queries WITHOUT pagination:"
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @has_pagination:false @relevant_rows_time:>5" --raw | jq '.data | length'

# Distribution analysis
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe 6h --raw | \
  jq -r '.data[].attributes.attributes | 
    {pagination: .has_pagination, time: .relevant_rows_time}' | \
  jq -s 'group_by(.pagination) | 
    map({pagination: .[0].pagination, avg_time: (map(.time) | add/length), count: length})'
```

### Finding Performance Issues

**Source Code**: Performance logging comes from `mono/sheets/cortex/ssrm/get_rows_utils.py`
- This module logs detailed query performance metrics
- Use different filters to find insights from these logs

```bash
# Query time distribution
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe 6h --raw | \
  jq -r '.data[].attributes.attributes.total_db_queries_time' | \
  awk '{total+=$1; n++} END {printf "Avg: %.3fs (n=%d)\n", total/n, n}'

# Cache hit rate
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --raw | \
  jq -r '.data[].attributes.attributes.cache_hit' | \
  grep -c true

# Slow sheet identification
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --raw | \
  jq -r 'select(.attributes.attributes.total_db_queries_time > 5) | 
         "\(.attributes.attributes.sheet): \(.attributes.attributes.total_db_queries_time)s"'
```

### Error Analysis
```bash
# Error rate by service
.venv/bin/python tools/datadog_explorer.py "logs:status:error" --raw | \
  jq -r '.data[].attributes.service' | sort | uniq -c | sort -rn

# Transaction rollbacks
.venv/bin/python tools/datadog_explorer.py "logs:\"rolling back transaction\"" --timeframe 1h

# Parse failures
.venv/bin/python tools/datadog_explorer.py "logs:\"Failed to parse\"" --timeframe 1h
```

## ðŸ” N+1 Query Investigation

### Finding N+1 Query Patterns
N+1 queries are best identified through log events with high `hydration_time` relative to `relevant_rows_time`.

```bash
# Find events with high hydration time (N+1 pattern indicator)
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries @hydration_time:>10" --timeframe 24h --event-urls

# Compare hydration vs query time
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --raw | \
  jq -r '.data[] | select(.attributes.attributes.hydration_time > (.attributes.attributes.relevant_rows_time * 2)) | 
    {sheet: .attributes.attributes.sheet, 
     rows: .attributes.attributes.total_row_count,
     query_time: .attributes.attributes.relevant_rows_time,
     hydration_time: .attributes.attributes.hydration_time,
     ratio: (.attributes.attributes.hydration_time / .attributes.attributes.relevant_rows_time)}'

# Example N+1 pattern: Sheet 150b9b12-8168-4d8c-a978-46697d04fbcf
# - 37 rows taking 36 seconds total
# - Query time: 4.77s (cached)
# - Hydration time: 31.08s (86% of total!)
# - This indicates ~1 second per row for hydration (classic N+1)
```

### Key Indicators of N+1 Problems
- **hydration_time >> relevant_rows_time**: Hydration taking 5-10x longer than query
- **Small row counts with high total time**: 37 rows taking 36 seconds
- **Cache hit but still slow**: Cache helps main query but not N+1 hydration queries
- **Per-row timing patterns**: Total time Ã· row count â‰ˆ 0.5-1s suggests individual queries

### Better Than APM Traces
- **Log events are more reliable**: APM traces often show "not available"
- **Event URLs persist longer**: Direct links to log events remain accessible
- **Attributes provide context**: hydration_time, cache_hit, row counts all visible
- **No sampling issues**: All performance logs are captured, unlike traces

## ðŸ”¬ Viewing Full Traces and SQL Queries

### Finding Events with SQL Query Details
```bash
# Query for slow performance with specific conditions
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries performance @cache_hit:true @relevant_rows_time:>5" --timeframe 1d

# Get direct event URLs to view in Datadog UI
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries @relevant_rows_time:>5" --event-urls

# The event URLs will take you to the Datadog Logs Explorer where you can:
# 1. Click on an event to expand it
# 2. Look for the "Traces" tab in the event details
# 3. Click "View Trace" to see the full APM trace
# 4. In the trace view, look for SQL query spans to see actual queries and their execution times
```

### Analyzing Trace Data
```bash
# Find APM traces with long durations
.venv/bin/python tools/datadog_explorer.py "traces:service:sheets @duration:>5000000000" --timeframe 1d

# Get trace IDs from log events
.venv/bin/python tools/datadog_explorer.py "logs:env:prod run_get_rows_db_queries @relevant_rows_time:>5" --raw | \
  jq -r '.data[] | select(.attributes.attributes.dd.trace_id) | .attributes.attributes.dd.trace_id'
```

### Datadog UI Navigation for SQL Analysis
1. **From Log Event to Trace**:
   - Use `--event-urls` to get direct links to log events
   - Click the event URL to open in Datadog
   - In event details, click "View Trace" (if available)
   - Navigate to SQL query spans in the trace flamegraph

2. **Trace View Features**:
   - Flamegraph shows execution timeline
   - SQL queries appear as database spans
   - Click on SQL spans to see:
     - Full query text
     - Execution time
     - Database connection details
     - Row count returned

3. **Finding Slow SQL Queries**:
   - Look for database spans with long durations
   - Check the `db.statement` attribute for the actual SQL
   - Use the flamegraph to identify query bottlenecks

4. **Direct Trace URL Access**:
   - Trace URLs follow this format:
     ```
     https://app.datadoghq.com/apm/trace/[TRACE_ID]?graphType=flamegraph&spanID=[SPAN_ID]
     ```
   - The API cannot retrieve the full flamegraph data shown in the UI
   - For detailed SQL analysis, you must use the Datadog web UI directly

### Example Event URL Format
```
https://app.datadoghq.com/logs?query=env%3Aprod%20run_get_rows_db_queries%20performance%20%40cache_hit%3Atrue
&event=AwAAAZkKTk_0JFfTIgAAABhBWmtLVGxJWEFBQVpvNVNUYlgtSkZnQUwAAAAkZjE5OTBhNTUtMzZhNS00NTRjLWI5ZWUtNzYwNTM3MTY5YTNhABAqnA
&agg_m=@relevant_rows_time
&agg_q=@matrix_size_category
```

## Key Findings from Investigation

From analyzing `get_rows` performance (logged by `mono/sheets/cortex/ssrm/get_rows_utils.py`):

### Application Logs
- **10% of queries are critical** (>1 second execution time)
- **Average DB query time: 0.704s** even with cache hits
- **Missing indexes** cause 48+ second queries (see final_report.md)
- **Common errors**: Transaction rollbacks, parse failures

### Performance Correlations (New Insights Using 4-Step Method)

**How these insights were discovered**:
1. **Looked at code**: Found logging in `mono/sheets/cortex/ssrm/get_rows_utils.py`
2. **Discovered attributes**: Extracted `has_pagination`, `matrix_size_category`, `has_group_loading`, etc.
3. **Experimented with filters**: Tested correlations between attributes and slowness
4. **Reported findings**:

- **Pagination is the key factor**: ALL slow queries (>5s relevant_rows_time) have pagination enabled
  ```bash
  # Discovery query that revealed this:
  @has_pagination:true @relevant_rows_time:>5  # Result: 100 queries
  @has_pagination:false @relevant_rows_time:>5 # Result: 0 queries
  ```
  
- **Large matrices with cache hits still slow**: Even with cache, large matrix queries take 14-23 seconds
  ```bash
  # Discovery query:
  @matrix_size_category:large @cache_hit:true @relevant_rows_time:>10
  ```
  
- **Group loading contributes to slowness**: 7 queries with group_loading exceed 5s total time
  ```bash
  # Discovery query:
  @has_group_loading:true @total_db_queries_time:>5
  ```

### APM Traces (NEW)
- **_get_relevant_rows_cached**: 2.8-3.1 second operations confirmed
- **/ssrm/get-rows**: API endpoints taking 3.7-10 seconds
- **Database spans**: Not captured separately, included in application spans
- **Slow operations**: 100+ traces >1 second found in 2-hour window

## Quick Reference

```bash
# Most useful commands for debugging (URLs included automatically!)
alias ddlogs='cd ~/Hebbia/sisu-notes && .venv/bin/python tools/datadog_explorer.py'

# Recent performance logs â†’ with clickable URL
ddlogs "logs:run_get_rows_db_queries" --timeframe 1h

# Current errors â†’ with clickable URL
ddlogs "logs:service:sheets status:error" --timeframe 15m

# Database load â†’ with clickable URL
ddlogs "avg:postgresql.connections{*}" --timeframe 1h
ddlogs "avg:postgresql.percent_usage_connections{*}" --timeframe 1h

# Database performance (APM traces) â†’ with clickable URL
ddlogs "avg:trace.postgres.connect{*}" --timeframe 1h
ddlogs "percentile:trace.postgres.query.time{*}:95" --timeframe 1h

# API latency â†’ with clickable URL
ddlogs "percentile:trace.request.duration{service:sheets}:95" --timeframe 1h

# CUSTOM TIMERANGES (NEW!)
# Query specific dates
ddlogs "logs:error" --timeframe "2025-01-03"  # Single day
ddlogs "logs:error" --timeframe "2025-01-03,2025-01-05"  # Date range

# Copy timestamps from Datadog web URLs
ddlogs "logs:error" --timeframe "1754539200000,1754711999999"  # From URL params

# Precise time windows
ddlogs "logs:error" --timeframe "2025-01-03T09:00:00,2025-01-03T17:00:00"  # Business hours

# Hide URLs when not needed
ddlogs "logs:error" --no-url

# Output raw JSON (no formatting, no URLs)
ddlogs "logs:error" --raw
```

## Important Limitations & Learnings

### API Limitations
- **Log Results**: Maximum 100 logs returned per query (use timeframe to narrow)
- **APM Traces**: Database operations not captured as separate spans in application traces
  - `resource_name:postgres` queries return no results
  - Database timing must be inferred from application-level logs
  - Full trace flamegraph data (including SQL queries) only available in web UI, not via API
- **Trace Details**: The API cannot retrieve the detailed breakdown shown in flamegraph view
  - SQL query text, execution plans, and detailed timings require web UI access
  - Trace IDs from logs often don't link properly to APM traces via API
  - **APM Trace URLs often show "trace is not available"** - traces are sampled and may expire
- **Metric Names**: PostgreSQL connection metrics not available via standard trace metrics
- **Connection Logs**: SQLAlchemy/psycopg2 connection timing not logged by default
- **N+1 Query Patterns**: Best identified through log event attributes like `hydration_time`
  - Look for high hydration_time relative to relevant_rows_time
  - Log events are more reliable than trace URLs for investigating N+1 issues

### Working Alternatives
- Use AWS CloudWatch for RDS Proxy metrics instead of Datadog APM
- Search for application-level slow query logs instead of connection traces
- Use `--raw` output with jq for complex filtering and counting

### Common Pitfalls
- Searching for `trace.postgres.*` metrics returns no data
- `resource_name:*postgres*` in logs doesn't match database operations
- Connection pool logs often about LaunchDarkly, not PostgreSQL

## Recent Tool Enhancements

### 2025-09-02 (Today - Latest v3)
- **Simplified Output Format**: Cleaner, more concise output that shows query on first line
  - Query shown immediately: `ðŸ” traces:resource_name:*get_rows* @duration:>2000000000 [2h]`
  - No verbose connection messages
  - Compact result display: `[1] 2025-09-01 22:37:59 | sheets | get_rows | 2357.81ms`
  - Single-line URL display: `ðŸ”— https://app.datadoghq.com/...`

### 2025-09-02 (Today - Latest v2)
- **Custom Timerange Support**: Added ability to specify exact date ranges using various formats
- **Unix Timestamp Support**: Accepts both seconds and milliseconds (auto-detected)
- **Date Range Queries**: Query specific days or date ranges like "2025-01-03,2025-01-05"
- **ISO Datetime Support**: Precise hour/minute ranges with ISO format
- **Web URL Compatibility**: Can extract timestamps from Datadog URLs (e.g., from_ts=1754539200000&to_ts=1754711999999)

Example matching your Datadog URL:
```bash
# Extract timestamps from URL: from_ts=1754539200000&to_ts=1754711999999
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe "1754539200000,1754711999999"

# Or use human-readable dates (Jan 3-5, 2025)
.venv/bin/python tools/datadog_explorer.py "logs:run_get_rows_db_queries" --timeframe "2025-01-03,2025-01-05"
```

### 2025-09-02 (Today - Latest)
- **Event-Specific URLs**: New `--event-urls` flag shows direct links to individual log events
- **Enhanced Log URLs**: URLs now include full viewing parameters (columns, aggregation, etc.)
- **Event ID Support**: Direct navigation to specific log events with unique event IDs

### 2025-09-02 (Today - Earlier)
- **Automatic URL Generation**: Tool now generates clickable Datadog web UI URLs by default
- **Direct Web Access**: Every query result includes a link to explore further in Datadog UI
- **Optional URL Hiding**: New `--no-url` flag to suppress URLs when not needed

### 2025-09-02 (Earlier)
- **APM Trace Support Added**: New `traces:` prefix for querying application performance traces
- **Duration Filtering**: Support for @duration filters to find slow operations
- **Raw Trace Analysis**: Full JSON output with --raw flag for detailed analysis
- **Confirmed Finding**: _get_relevant_rows_cached operations taking 2.8-3.1 seconds

## Troubleshooting

- **SSL Warning**: Ignore LibreSSL warnings - non-critical
- **No data**: Expand timeframe or check service name
- **Rate limit**: 1000 requests/hour for metrics
- **Authentication**: Verify keys in tools/config.py
- **Empty results**: Try broader search terms, check service names
- **No database spans**: Database operations included in application spans, not separate
